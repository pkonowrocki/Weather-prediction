{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WindCodesComparison.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkonowrocki/Weather-prediction/blob/master/WindCodesComparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTH8-1u_tLb0",
        "colab_type": "code",
        "outputId": "14ffb29d-cf9a-4ee5-90af-603446ebd4ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "#boilerplate code\n",
        "import subprocess\n",
        "file_id = '1XfiON89EFCsw5zhtD4hq1hn5Z21vGzpG'\n",
        "subprocess.run(['pip', 'install', 'PyDrive'])\n",
        "subprocess.run(['apt-get', 'install', 'unzip'])\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "downloaded = drive.CreateFile({'id':file_id})\n",
        "downloaded.GetContentFile('Dataset.zip')\n",
        "if not os.path.exists('./Dataset'):\n",
        "  subprocess.run(['unzip', './Dataset.zip'])\n",
        "print(f'{\"\".join([\"-\" for _ in range(10)])}DATA READY{\"\".join([\"-\" for _ in range(10)])}')\n",
        "\n",
        "#code\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "    print('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('cpu')\n",
        "\n",
        "def testNetwork(Xtest, Ytest, net, criterion):\n",
        "  x = torch.Tensor(Xtest).to(device)\n",
        "  output = net(x)\n",
        "  loss = criterion(output, torch.Tensor(np.array([Ytest]).T).to(device))\n",
        "  return torch.mean(loss).cpu().detach().numpy(), torch.std(loss).cpu().detach().numpy()\n",
        "\n",
        "def trainNetwork(path, code, net = None, epochs = None, criterion = None, checkEvery = None, optimizer = None, val = 0.0, scaler = None, batch = 1, gradClipping = 0, seed = 0):\n",
        "  torch.manual_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  Xtrain = np.genfromtxt(f'{path}/{code}-train-input.csv', delimiter=',')\n",
        "  Ytrain = np.genfromtxt(f'{path}/{code}-train-output.csv', delimiter=',')\n",
        "  Xtest = np.genfromtxt(f'{path}/{code}-test-input.csv', delimiter=',')\n",
        "  Ytest = np.genfromtxt(f'{path}/{code}-test-output.csv', delimiter=',')\n",
        "  if scaler is None:\n",
        "    scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
        "  Xtrain = scaler.transform(Xtrain)\n",
        "  Xtest = scaler.transform(Xtest)\n",
        "\n",
        "  if not val == 0.0:\n",
        "    n = int(len(Ytrain)*val)+1 if int(len(Ytrain)*val)+1 < len(Ytrain) else int(len(Ytrain)*val)\n",
        "    idxs = np.random.choice(np.arange(0, len(Ytrain), 1), n)\n",
        "    Xval = Xtrain[idxs]\n",
        "    Yval = Ytrain[idxs]\n",
        "    Xtrain = np.delete(Xtrain, idxs, axis=0)\n",
        "    Ytrain = np.delete(Ytrain, idxs)\n",
        "  else:\n",
        "    Xval = None\n",
        "\n",
        "  if epochs is None:\n",
        "    epochs = 1000\n",
        "  if checkEvery is None:\n",
        "    checkEvery = 5\n",
        "  if net is None:\n",
        "    numInputs = Xtrain.shape[1]\n",
        "    numOutputs = 1\n",
        "    hiddenSize = 50\n",
        "    net = nn.Sequential(\n",
        "      nn.Linear(numInputs, 2*hiddenSize),\n",
        "      nn.ELU(),\n",
        "      nn.Linear(2*hiddenSize, hiddenSize),\n",
        "      nn.ELU(),\n",
        "      nn.Linear(hiddenSize, numOutputs)).to(device)\n",
        "  if criterion is None:\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "  if optimizer is None:\n",
        "    optimizer = optim.Adadelta(net.parameters())\n",
        "\n",
        "  net.to(device)\n",
        "\n",
        "  if batch == 1:\n",
        "    splitXtrain = Xtrain\n",
        "    splitYtrain = Ytrain\n",
        "  else:\n",
        "    batch = int(len(Ytrain)/batch)\n",
        "    splitXtrain = np.array_split(Xtrain, batch)\n",
        "    splitYtrain = np.array_split(Ytrain, batch)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    runningLoss = 0.0\n",
        "    for i, x in enumerate(splitXtrain, 0):\n",
        "      if np.any(np.isnan(x)):\n",
        "        raise('NaN value in input')\n",
        "      if np.any(np.isnan(splitYtrain[i])):\n",
        "        raise('NaN value in target')\n",
        "      optimizer.zero_grad()\n",
        "      y = torch.Tensor(np.array([splitYtrain[i]]).T).to(device)\n",
        "      x = torch.Tensor(x).to(device)\n",
        "      output = net(x)\n",
        "      if np.any(np.isnan(output.cpu().detach().numpy())):\n",
        "        raise('NaN value in output')\n",
        "      loss = torch.mean(criterion(output, y))\n",
        "      loss.backward()\n",
        "      if not gradClipping == 0:\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), gradClipping)\n",
        "      optimizer.step()\n",
        "      runningLoss += loss.item()\n",
        "\n",
        "    if epoch % checkEvery == checkEvery-1 or epoch == 0:\n",
        "      if not Xval is None:\n",
        "        lossVal, stdVal  = testNetwork(Xval, Yval, net, criterion)\n",
        "      \n",
        "      lossTest, stdTest = testNetwork(Xtest, Ytest, net, criterion)\n",
        "      print(f'{epoch}, {runningLoss/len(splitYtrain)}, {lossTest}, {stdTest}{\", \" + str(lossVal) +\", \" + str(stdVal) if not Xval is None else \"\"}')\n",
        "  \n",
        "  lossVal, _ = testNetwork(Xtest, Ytest, net, criterion)\n",
        "  print(f'Finally: {lossVal}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for _ in range(100):\n",
        "  seed = np.random.randint(np.iinfo(np.int32).max)\n",
        "  print(f'Clouds Okta Wind Gray (seed: {seed})')\n",
        "  trainNetwork('./Dataset/Temperature/Imputation', 'CloudsOktaWindGray', val = 0.2, batch = 32, gradClipping = 2, seed = seed)\n",
        "  print(f'Clouds Okta Wind Natural (seed: {seed})')\n",
        "  trainNetwork('./Dataset/Temperature/Imputation', 'CloudsOktaWindNatural', val = 0.2, batch = 32, gradClipping = 2, seed = seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------DATA READY----------\n",
            "cuda\n",
            "Clouds Okta Wind Gray (seed: 384854952)\n",
            "0, 34.92008916330544, 13.724742889404297, 23.416324615478516, 15.274144, 25.84031\n",
            "4, 4.932138558267515, 8.918859481811523, 16.4918155670166, 8.031231, 15.426917\n",
            "9, 4.4165323609204, 7.123758792877197, 13.016109466552734, 6.2501707, 13.5161915\n",
            "14, 4.2001094734900954, 7.084744453430176, 12.576220512390137, 6.133829, 12.867029\n",
            "19, 4.038742556442301, 6.721884727478027, 12.63906192779541, 5.8372955, 12.8546295\n",
            "24, 3.9120079915954435, 6.690328121185303, 13.286142349243164, 5.742623, 13.222185\n",
            "29, 3.8149447335470548, 6.469637393951416, 12.236225128173828, 5.553243, 12.069746\n",
            "34, 3.707346611595773, 6.497461795806885, 12.966470718383789, 5.518493, 12.969676\n",
            "39, 3.591226127579228, 6.589836597442627, 12.73996639251709, 5.7370853, 12.6984005\n",
            "44, 3.4791072095982183, 6.61887788772583, 13.1063871383667, 5.597049, 13.060882\n",
            "49, 3.3709199760447848, 6.575546741485596, 12.885384559631348, 5.736109, 13.13862\n",
            "54, 3.2926118587228386, 6.725503921508789, 13.059752464294434, 5.740163, 12.8152\n",
            "59, 3.1846090322320078, 7.0244269371032715, 13.825203895568848, 5.982997, 14.159333\n",
            "64, 3.1052122516678526, 7.140567302703857, 15.158616065979004, 5.998142, 13.796938\n",
            "69, 3.045141677626155, 7.4053568840026855, 14.426772117614746, 6.219725, 14.359904\n",
            "74, 3.0006832288682976, 7.405056953430176, 14.290818214416504, 6.2412443, 13.959797\n",
            "79, 2.9406779851135494, 7.762509822845459, 15.630704879760742, 6.4880023, 14.579884\n",
            "84, 2.907414724542336, 8.107664108276367, 17.511274337768555, 6.8274636, 16.2028\n",
            "89, 2.8717713570504477, 7.334048748016357, 15.317320823669434, 6.2375445, 15.264313\n",
            "94, 2.8210757168663014, 7.95503568649292, 16.690378189086914, 6.853008, 16.886202\n",
            "99, 2.7920340178816607, 7.88299036026001, 15.57708740234375, 6.8043656, 19.581305\n",
            "104, 2.774579168236875, 8.483180046081543, 16.378602981567383, 7.2479243, 17.541082\n",
            "109, 2.6914690688768506, 7.990410327911377, 15.634464263916016, 7.1235223, 22.44306\n",
            "114, 2.687248119237748, 8.210866928100586, 17.248291015625, 7.2106037, 19.672665\n",
            "119, 2.6570532481262696, 8.682710647583008, 17.80125617980957, 7.6757617, 26.382763\n",
            "124, 2.643170357992252, 8.11955738067627, 15.702982902526855, 7.107297, 21.838255\n",
            "129, 2.599392059706635, 8.481973648071289, 16.317110061645508, 7.304683, 19.27333\n",
            "134, 2.604367685008359, 8.821277618408203, 16.742441177368164, 7.59605, 20.564024\n",
            "139, 2.5740151792216355, 8.821243286132812, 17.130876541137695, 7.4523816, 19.91345\n",
            "144, 2.603381569380368, 8.883218765258789, 18.437902450561523, 7.507623, 19.123163\n",
            "149, 2.5512508628043262, 8.774625778198242, 17.32159423828125, 7.4334354, 18.930882\n",
            "154, 2.5452136395104006, 8.916399002075195, 17.782873153686523, 7.389319, 17.339436\n",
            "159, 2.5590322307306965, 9.433259010314941, 19.94832992553711, 7.8824186, 19.325102\n",
            "164, 2.5131615692531906, 9.934918403625488, 21.55532455444336, 8.282257, 22.386772\n",
            "169, 2.5010491723106023, 9.683277130126953, 21.139841079711914, 8.124633, 21.893536\n",
            "174, 2.477995439154374, 9.795759201049805, 22.00555419921875, 8.277754, 25.903036\n",
            "179, 2.429481003094803, 10.235762596130371, 23.607372283935547, 8.53744, 29.333696\n",
            "184, 2.457335185678877, 9.583257675170898, 21.4090518951416, 8.325868, 39.768585\n",
            "189, 2.443945186881921, 9.385351181030273, 21.02004051208496, 8.043535, 35.324074\n",
            "194, 2.4892358070973195, 9.355533599853516, 20.86446189880371, 8.198638, 35.881054\n",
            "199, 2.432374455889453, 9.385838508605957, 21.291234970092773, 8.333822, 50.838234\n",
            "204, 2.451194502622921, 9.42673110961914, 20.514495849609375, 8.166087, 37.763844\n",
            "209, 2.420349050474502, 9.563210487365723, 21.64530372619629, 8.237653, 32.370773\n",
            "214, 2.3990857641805303, 9.301008224487305, 21.164113998413086, 7.976807, 36.82385\n",
            "219, 2.4338105862307082, 9.488808631896973, 21.61683464050293, 7.9238734, 31.922846\n",
            "224, 2.418900535913644, 9.468729972839355, 22.08355140686035, 7.877382, 32.45044\n",
            "229, 2.407667420111048, 9.865918159484863, 24.598426818847656, 8.0933485, 24.156435\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}