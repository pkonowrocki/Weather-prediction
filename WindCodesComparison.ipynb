{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WindCodesComparison.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkonowrocki/Weather-prediction/blob/master/WindCodesComparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTH8-1u_tLb0",
        "colab_type": "code",
        "outputId": "4600509a-970e-4063-8698-d78389859f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "#boilerplate code\n",
        "import subprocess\n",
        "file_id = '1XfiON89EFCsw5zhtD4hq1hn5Z21vGzpG'\n",
        "subprocess.run(['pip', 'install', 'PyDrive'])\n",
        "subprocess.run(['apt-get', 'install', 'unzip'])\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "downloaded = drive.CreateFile({'id':file_id})\n",
        "downloaded.GetContentFile('Dataset.zip')\n",
        "if not os.path.exists('./Dataset'):\n",
        "  subprocess.run(['unzip', './Dataset.zip'])\n",
        "print(f'{\"\".join([\"-\" for _ in range(10)])}DATA READY{\"\".join([\"-\" for _ in range(10)])}')\n",
        "\n",
        "#code\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "    print('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('cpu')\n",
        "\n",
        "def testNetwork(Xtest, Ytest, net, criterion):\n",
        "  x = torch.Tensor(Xtest).to(device)\n",
        "  output = net(x)\n",
        "  loss = criterion(output, torch.Tensor(np.array([Ytest]).T).to(device))\n",
        "  return loss.item()/len(Ytest), output\n",
        "\n",
        "def trainNetwork(path, code, net = None, epochs = None, criterion = None, checkEvery = None, optimizer = None, val = 0.0, scaler = None, batch = 1, gradClipping = 0, seed = 0):\n",
        "  torch.manual_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  Xtrain = np.genfromtxt(f'{path}/{code}-train-input.csv', delimiter=',')\n",
        "  Ytrain = np.genfromtxt(f'{path}/{code}-train-output.csv', delimiter=',')\n",
        "  Xtest = np.genfromtxt(f'{path}/{code}-test-input.csv', delimiter=',')\n",
        "  Ytest = np.genfromtxt(f'{path}/{code}-test-output.csv', delimiter=',')\n",
        "  if scaler is None:\n",
        "    scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
        "  Xtrain = scaler.transform(Xtrain)\n",
        "  Xtest = scaler.transform(Xtest)\n",
        "\n",
        "  if not val == 0.0:\n",
        "    n = int(len(Ytrain)*val)+1 if int(len(Ytrain)*val)+1 < len(Ytrain) else int(len(Ytrain)*val)\n",
        "    idxs = np.random.choice(np.arange(0, len(Ytrain), 1), n)\n",
        "    Xval = Xtrain[idxs]\n",
        "    Yval = Ytrain[idxs]\n",
        "    Xtrain = np.delete(Xtrain, idxs, axis=0)\n",
        "    Ytrain = np.delete(Ytrain, idxs)\n",
        "  else:\n",
        "    Xval = None\n",
        "\n",
        "  if epochs is None:\n",
        "    epochs = 1000\n",
        "  if checkEvery is None:\n",
        "    checkEvery = 5\n",
        "  if net is None:\n",
        "    numInputs = Xtrain.shape[1]\n",
        "    numOutputs = 1\n",
        "    hiddenSize = 50\n",
        "    net = nn.Sequential(\n",
        "      nn.Linear(numInputs, 2*hiddenSize),\n",
        "      nn.ELU(),\n",
        "      nn.Linear(2*hiddenSize, hiddenSize),\n",
        "      nn.ELU(),\n",
        "      nn.Linear(hiddenSize, numOutputs)).to(device)\n",
        "  if criterion is None:\n",
        "    criterion = nn.MSELoss(reduction='sum')\n",
        "  if optimizer is None:\n",
        "    optimizer = optim.Adadelta(net.parameters())\n",
        "\n",
        "  net.to(device)\n",
        "\n",
        "  if batch == 1:\n",
        "    splitXtrain = Xtrain\n",
        "    splitYtrain = Ytrain\n",
        "  else:\n",
        "    batch = int(len(Ytrain)/batch)\n",
        "    splitXtrain = np.array_split(Xtrain, batch)\n",
        "    splitYtrain = np.array_split(Ytrain, batch)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    runningLoss = 0.0\n",
        "    for i, x in enumerate(splitXtrain, 0):\n",
        "      if np.any(np.isnan(x)):\n",
        "        raise('NaN value in input')\n",
        "      if np.any(np.isnan(splitYtrain[i])):\n",
        "        raise('NaN value in target')\n",
        "      optimizer.zero_grad()\n",
        "      y = torch.Tensor(np.array([splitYtrain[i]]).T).to(device)\n",
        "      x = torch.Tensor(x).to(device)\n",
        "      output = net(x)\n",
        "      if np.any(np.isnan(output.cpu().detach().numpy())):\n",
        "        raise('NaN value in output')\n",
        "      loss = criterion(output, y)\n",
        "      loss.backward()\n",
        "      if not gradClipping == 0:\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), gradClipping)\n",
        "      optimizer.step()\n",
        "      runningLoss += loss.item()\n",
        "\n",
        "    if epoch % checkEvery == checkEvery-1 or epoch == 0:\n",
        "      if not Xval is None:\n",
        "        lossVal, _ = testNetwork(Xval, Yval, net, criterion)\n",
        "      else:  \n",
        "        lossVal, _ = testNetwork(Xtest, Ytest, net, criterion)\n",
        "      print(f'{epoch}, {runningLoss/len(Ytrain)}, {lossVal}')\n",
        "  \n",
        "  lossVal, _ = testNetwork(Xtest, Ytest, net, criterion)\n",
        "  print(f'Finally: {lossVal}')\n",
        "\n",
        "\n",
        "\n",
        "for _ in range(100):\n",
        "  seed = np.random.randint(np.iinfo(np.int32).max)\n",
        "  print(f'Clouds Okta Wind Gray (seed: {seed})')\n",
        "  trainNetwork('./Dataset/Temperature/Imputation', 'CloudsOktaWindGray', val = 0.2, batch = 32, gradClipping = 2, seed = seed)\n",
        "  print(f'Clouds Okta Wind Natural (seed: {seed})')\n",
        "  trainNetwork('./Dataset/Temperature/Imputation', 'CloudsOktaWindNatural', val = 0.2, batch = 32, gradClipping = 2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------DATA READY----------\n",
            "cuda\n",
            "Clouds Okta Wind Gray (seed: 1259631606)\n",
            "Sequential(\n",
            "  (0): Linear(in_features=65, out_features=100, bias=True)\n",
            "  (1): ELU(alpha=1.0)\n",
            "  (2): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (3): ELU(alpha=1.0)\n",
            "  (4): Linear(in_features=50, out_features=1, bias=True)\n",
            ")\n",
            "0, 32.229513796152304, 13.979010387859514\n",
            "4, 5.023434774933289, 6.4963973053788715\n",
            "9, 4.457913987462334, 6.026228373029591\n",
            "14, 4.163417206331634, 5.46961421460177\n",
            "19, 4.022195913301164, 5.207749628387721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-84e513844a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Clouds Okta Wind Gray (seed: {seed})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m   \u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Dataset/Temperature/Imputation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CloudsOktaWindGray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradClipping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Clouds Okta Wind Natural (seed: {seed})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Dataset/Temperature/Imputation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CloudsOktaWindNatural'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradClipping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-84e513844a12>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(path, code, net, epochs, criterion, checkEvery, optimizer, val, scaler, batch, gradClipping, seed)\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgradClipping\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradClipping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m       \u001b[0mrunningLoss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adadelta.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0macc_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}